apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: "{{ ti.task_id }}-{{ ds_nodash }}-{{ ti.try_number }}"
  namespace: spark
spec:
  type: Scala
  mode: cluster
  image: "asia-docker.pkg.dev/pocz-389704/docker/spark:1.1.3"
  imagePullPolicy: IfNotPresent
  mainClass: com.sirclo.spark.Main
  mainApplicationFile: local:///opt/app/spark/target/scala-2.12/Spark_2.12_3.3.2_1.0.0-RELEASE.jar
  sparkVersion: 3.3.2
  restartPolicy:
    type: Never
  timeToLiveSeconds: 30
  driver:
    cores: 0.1
    coreLimit: "1200m"
    memory: "256m"
    labels:
      version: 3.3.2
    serviceAccount: spark-spark
  executor:
    cores: 0.1
    instances: 1
    memory: "256m"
    labels:
      version: 3.3.2
  dynamicAllocation:
    enabled: True
    initialExecutors: 1
    minExecutors: 1
    maxExecutors: 3
    shuffleTrackingTimeout: ~
